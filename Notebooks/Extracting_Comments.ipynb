{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: A1III_DQU4I\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_video_id(url):\n",
    "    # Regular expression pattern to extract video ID\n",
    "    pattern = r\"(?:https?:\\/\\/(?:www\\.)?youtube\\.com\\/(?:[^\\/\\n\\s]+\\/\\S+\\/|(?:v|e(?:mbed)?)\\/|\\S*?[?&]v=)|youtu\\.be\\/)([a-zA-Z0-9_-]{11})\"\n",
    "    \n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid YouTube URL\")\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.youtube.com/watch?v=A1III_DQU4I\"\n",
    "video_id = extract_video_id(url)\n",
    "print(f\"Video ID: {video_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Create a service to interact with the YouTube API\n",
    "youtube = build('youtube', 'v3', developerKey=os.getenv('YOUTUBE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_comments(video_id):\n",
    "    comments = []\n",
    "    request = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        videoId=video_id,\n",
    "        maxResults=100,  # You can modify this to get more results (max 100 per request)\n",
    "        textFormat=\"plainText\"\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    while request:\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)\n",
    "\n",
    "        # Check if there are more pages of comments\n",
    "        if 'nextPageToken' in response:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                pageToken=response['nextPageToken'],  # This is the key for pagination\n",
    "                maxResults=100,\n",
    "                textFormat=\"plainText\"\n",
    "            )\n",
    "            response = request.execute()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return comments\n",
    "\n",
    "# Fetch comments\n",
    "comments = get_comments(video_id=video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['مشكلة ملفات csv لا تعرض جميع التعليقات وايضا لا تعرضها اصلا لا يظهر سوى حروف مقطعة ورموز \\nولا يظهر سوى اخر ٢٠٠ خانة\\n\\nاتمنى لو يرجعون ملف html ، افضل من هذا',\n",
       " 'Hello, thank you for the great informative video. I will need to extract about 4 million comments from a video. Do you think it would be possible on my local computer with this code?\\nI am currently trying but taking a lot of time for sure.',\n",
       " \"OMG... This just saved me potentially hours, days, weeks, etc. Was literally like meh even if I spend the next couple of hours trying to figure out a way to copy the 17,000 comments ( not nested ) I need from this 1 video for my project & it doesn't work out, I will still be better off considering my pc can only load like 10 comments when scrolling per second & then it crashes after like max 1000. YOU ARE AN ABSOLUTE LIFESAVER & if I wasn't so goddamn broke I would genuinely tip you heavy for this. Thanks brother!\",\n",
       " 'Hi from Brazil, I loved the video. I would really like to know how to extract it from the YouTube chat',\n",
       " 'Wowsers. This went right over my head. It assumes lots of prerequisite knowledge.',\n",
       " 'Hey, do you know a way to find all the videos with the phrase written in the comments like \"this is the best song ever\"? thank you',\n",
       " 'i dont have gogle cloud, dont ways again?',\n",
       " \"Man thanks a ton for this bro.  Great stuff.  Didn't realize it was this easy\",\n",
       " 'Thank you, it works well.\\nIt doesn\\'t however handle the scenario of a playlist containing a video marked as \"private\".\\nCan\\'t post the error log here on YT :(',\n",
       " '✅ Perfect',\n",
       " 'thanks it is really helpful 😘',\n",
       " \"Great content! I have 2 questions:\\n1. Will this work on YT shorts as well?\\n2. What's the limit/quota for the free YouTube API, something like 10,000 comments per day?\",\n",
       " 'How to do it for just a video and not a playlist?',\n",
       " \"thanks man, it's really work, have a nice day :)\",\n",
       " 'Thank you a lot with this video, you saved me with a university project, after the page X blocked the API for all of us, thank you a lot',\n",
       " \"Hi, do I need to install googleap[iclient. cause it says no module named 'googleapiclient'\",\n",
       " 'Man it works only for a video??',\n",
       " 'Can I also use this for single videos?',\n",
       " 'u r amazing😍, but can u suggest me how to retrieve all comments just for one video',\n",
       " \"You're such a blessing.\\n\\nI spent ages trying to figure out how to extract comments on a topic on Twitter.\\nI recently thought about extracting comments from a YouTube video about that topic and came across your video.\\n\\nThank you so so much.\",\n",
       " 'Hi, it\\'s amazing but I\\'ve got an error: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=qK0uRo5UGMU&textFormat=plainText&maxResults=100&key=AIzaSyCk31N4Rb_sykBbSHRBsGVevYIftRuONJU&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{\\'message\\': \\'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\\', \\'domain\\': \\'youtube.commentThread\\', \\'reason\\': \\'videoNotFound\\', \\'location\\': \\'videoId\\', \\'locationType\\': \\'parameter\\'}]\"\\n\\nWhat can I do? Thanks.',\n",
       " 'You are truly amazing! Thankyou so much.',\n",
       " 'interesting. I think it would take me a bit to fully understand how to do this. Is there a program or something out there to scan all that data and find keywords, or most found phrases etc... or would you just filter in excel to find such data?',\n",
       " \"hi sir, I got this error. ModuleNotFoundError                       Traceback (most recent call last)\\r\\nCell In[57], line 3\\r\\n      1 from googleapiclient.discovery import build\\r\\n      2 import pandas as pd\\r\\n----> 3 from google.colab import files, drive\\r\\n      4 import getpas\\r\\n\\r\\nModuleNotFoundError: No module named 'google.colab'\",\n",
       " 'Do you know if it is possible that the number of replies shown in the browser doesnt match with the number of comments fetched using the API? I am trying to get comments to a specific video and the number of comments I receive are 5-6 more than what is shown in the browser. My theory is that since youtube hides certain comments (such as ones contains urls), so those are not shown in the browser but the API can still access it. I still need to test it.',\n",
       " 'Thanks a lot for the video, is there a way we can know how long it is going to take for the code to get all comments. Something like a tqdm? The infinite while loop makes things tricky but maybe you can find a way :)',\n",
       " 'Man thank you very much! Your code really helps me with my bachelors degree! It is my second day with these codes and you really did a good job for a rookie me!']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
